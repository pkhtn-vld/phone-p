<!doctype html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>webrtc-minimal</title>
  <style>
    body {
      font-family: Arial, Helvetica, sans-serif;
      padding: 16px
    }

    button {
      padding: 8px 12px;
      margin: 6px
    }

    #log {
      white-space: pre-wrap;
      background: #f6f6f6;
      padding: 8px;
      border-radius: 6px;
      height: 240px;
      overflow: auto
    }
  </style>
</head>

<body>
  <h3>WebRTC minimal demo</h3>
  <div>
    <button id="btnLocal">Разрешить микрофон</button>
    <button id="btnCall">Позвонить (всем)</button>
    <button id="btnHang">Завершить</button>
  </div>
  <div>Ваш id: <span id="myId">-</span></div>
  <div>Логи:</div>
  <div id="log"></div>


  <audio id="remoteAudio" autoplay playsinline></audio>

  <script>
    (function () {
      const logEl = document.getElementById('log');
      const myIdEl = document.getElementById('myId');
      function log(...args) { console.log(...args); logEl.textContent += args.map(a => typeof a === 'object' ? JSON.stringify(a) : String(a)).join(' ') + '\n'; logEl.scrollTop = logEl.scrollHeight; }

      // кнопка для пользовательского жеста — создаём, если её нет в DOM
      let audioEnabled = false;
      let enableBtn = document.getElementById('enableAudioBtn');
      if (!enableBtn) {
        enableBtn = document.createElement('button');
        enableBtn.id = 'enableAudioBtn';
        enableBtn.textContent = 'Включить звук (нужен для авто-воспроизведения)';
        enableBtn.style.margin = '6px';
        document.body.insertBefore(enableBtn, document.getElementById('log'));
      }

      const remoteAudio = document.getElementById('remoteAudio');
      // если браузер требует пользовательский жест, держим audio muted до нажатия
      remoteAudio.muted = true;

      enableBtn.addEventListener('click', async () => {
        try {
          // пытаемся play() — если получилось, считаем что autoplay разрешён
          await remoteAudio.play();
          remoteAudio.muted = false; // можно убрать заглушку
          audioEnabled = true;
          enableBtn.textContent = 'Звук включён';
          enableBtn.disabled = true;
          log('// audio enabled by user gesture');
        } catch (e) {
          // если play() не удалось — оставляем muted, но помечаем что пользователь сделал жест
          audioEnabled = true;
          enableBtn.textContent = 'Жест зафиксирован — звук разрешён после приема потока';
          enableBtn.disabled = true;
          log('// audio enable attempted, play() failed (это нормально в некоторых браузерах):', String(e));
        }
      });

      // WebSocket
      const wsProto = (location.protocol === 'https:') ? 'wss' : 'ws';
      const ws = new WebSocket(wsProto + '://' + location.host + '/ws');
      let myId = null;
      let pc = null;
      let localStream = null;

      // добавляем публичный STUN, без TURN — для быстрых тестов
      const iceConfig = {
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' }
          // для реальных интернет-сцен добавьте TURN здесь
          // { urls: 'turn:your-turn.example:3478', username: 'user', credential: 'pass' }
        ]
      };

      ws.addEventListener('open', () => log('// ws OPEN'));
      ws.addEventListener('message', async (ev) => {
        let msg; try { msg = JSON.parse(ev.data); } catch (e) { return; }
        log('// ws IN', msg.type || msg);

        if (msg.type === 'welcome') { myId = msg.id; myIdEl.textContent = myId; return; }

        if (msg.type === 'offer') {
          log('// got offer');
          if (pc) { pc.close(); pc = null; }
          pc = new RTCPeerConnection(iceConfig);
          pc.onicecandidate = (e) => { if (e.candidate) ws.send(JSON.stringify({ type: 'candidate', candidate: e.candidate })); };
          // ---------- ЗАМЕНИТЬ: pc.ontrack (используется в обоих местах: при создании pc для caller и для callee) ----------
          // замените текущую реализацию pc.ontrack = (e) => { ... } на этот фрагмент
          pc.ontrack = (e) => {
            try {
              log('// ontrack', e.streams);
              const remoteStream = (e.streams && e.streams[0]) || e.stream || null;
              const aud = remoteAudio; // <audio id="remoteAudio">
              aud.srcObject = remoteStream;

              // comment: мониторинг удалённого потока
              // создаём/переиспользуем AudioContext для remote
              if (!window.remoteAudioContext) {
                window.remoteAudioContext = new (window.AudioContext || window.webkitAudioContext)();
              }
              const rac = window.remoteAudioContext;

              // очистим предыдущий интервал, если был
              if (window._remoteAnalyserInterval) {
                clearInterval(window._remoteAnalyserInterval);
                window._remoteAnalyserInterval = null;
              }

              try {
                const remoteSource = rac.createMediaStreamSource(remoteStream);
                const remoteAnalyser = rac.createAnalyser();
                remoteAnalyser.fftSize = 2048;
                remoteSource.connect(remoteAnalyser);
                const data = new Uint8Array(remoteAnalyser.fftSize);

                // измеряем RMS удалённого аудио
                window._remoteAnalyserInterval = setInterval(() => {
                  try {
                    remoteAnalyser.getByteTimeDomainData(data);
                    let sum = 0;
                    for (let i = 0; i < data.length; i++) {
                      const v = (data[i] - 128) / 128;
                      sum += v * v;
                    }
                    const rms = Math.sqrt(sum / data.length);
                    const rms100 = Math.round(rms * 1000) / 1000;
                    log(`// remote-audio-level ${rms100}`);
                    // отправка на сервер для диагностики
                    try {
                      fetch('/debug/log', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                          ts: new Date().toISOString(),
                          src: 'client-audio-monitor',
                          kind: 'remote_audio_level',
                          data: { level: rms100 }
                        })
                      }).catch(() => {/* ignore */ });
                    } catch (e) { }
                  } catch (err) { /* ignore per-interval errors */ }
                }, 250);
              } catch (err) {
                log('// remote analyser setup failed', String(err));
              }

              // comment: попытка play() — если пользователь уже сделал жест, play выполнится; иначе будет ошибка и мы ждём жеста
              if (audioEnabled) {
                aud.muted = false;
                aud.play().then(() => { log('// remote audio play OK'); })
                  .catch((err) => { log('// remote audio play failed', String(err)); });
              } else {
                // если пользовательский жест не сделан — оставляем muted и ждем нажатия enableAudioBtn
                aud.muted = true;
                log('// ontrack but waiting for user gesture');
              }

            } catch (e) {
              log('// ontrack handler failed', e);
            }
          };


          if (localStream) localStream.getTracks().forEach(t => pc.addTrack(t, localStream));
          await pc.setRemoteDescription({ type: 'offer', sdp: msg.sdp });
          const ans = await pc.createAnswer();
          await pc.setLocalDescription(ans);
          ws.send(JSON.stringify({ type: 'answer', sdp: ans.sdp }));
          log('// answer sent');
          return;
        }

        if (msg.type === 'answer') {
          log('// got answer');
          if (!pc) return;
          try { await pc.setRemoteDescription({ type: 'answer', sdp: msg.sdp }); log('// remoteDescription(answer) set'); } catch (e) { log('// setRemoteDescription(answer) failed', e); }
          return;
        }

        if (msg.type === 'candidate') {
          log('// got candidate');
          if (!pc) { log('// no pc yet — ignored candidate'); return; }
          try { await pc.addIceCandidate(msg.candidate); log('// added candidate'); } catch (e) { log('// addIceCandidate failed', e); }
          return;
        }
      });

      // ---------- ЗАМЕНИТЬ: handler для кнопки "Разрешить микрофон" ----------
      // заменяет существующий document.getElementById('btnLocal').addEventListener('click', ... )
      document.getElementById('btnLocal').addEventListener('click', async () => {
        // comment: acquire local mic & start analyser
        try {
          localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          log('// local stream acquired', localStream.getTracks().map(t => t.kind));

          // comment: создаём AudioContext для локального анализа (видно, что микрофон даёт сигнал)
          if (!window.localAudioContext) {
            window.localAudioContext = new (window.AudioContext || window.webkitAudioContext)();
          }
          const lac = window.localAudioContext;

          // comment: если уже был созднан source — очистим
          if (window._localAnalyserInterval) {
            clearInterval(window._localAnalyserInterval);
            window._localAnalyserInterval = null;
          }

          const source = lac.createMediaStreamSource(localStream);
          const analyser = lac.createAnalyser();
          analyser.fftSize = 2048;
          source.connect(analyser);
          const data = new Uint8Array(analyser.fftSize);

          // comment: интервал измерения RMS уровня (каждые 250ms)
          window._localAnalyserInterval = setInterval(() => {
            try {
              analyser.getByteTimeDomainData(data);
              // compute RMS (0..1)
              let sum = 0;
              for (let i = 0; i < data.length; i++) {
                const v = (data[i] - 128) / 128;
                sum += v * v;
              }
              const rms = Math.sqrt(sum / data.length);
              const rms100 = Math.round(rms * 1000) / 1000;
              log(`// local-audio-level ${rms100}`);
              // отправим на сервер для общей трассировки
              try {
                fetch('/debug/log', {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({
                    ts: new Date().toISOString(),
                    src: 'client-audio-monitor',
                    kind: 'local_audio_level',
                    data: { level: rms100 }
                  })
                }).catch(() => {/* ignore network errors */ });
              } catch (e) { }
            } catch (e) { /* ignore */ }
          }, 250);

        } catch (e) {
          log('// getUserMedia failed', e);
        }
      });


      document.getElementById('btnCall').addEventListener('click', async () => {
        log('// call: start');
        if (pc) { pc.close(); pc = null; }
        pc = new RTCPeerConnection(iceConfig);
        pc.onicecandidate = (e) => { if (e.candidate) ws.send(JSON.stringify({ type: 'candidate', candidate: e.candidate })); };
        // ---------- ЗАМЕНИТЬ: pc.ontrack (используется в обоих местах: при создании pc для caller и для callee) ----------
        // замените текущую реализацию pc.ontrack = (e) => { ... } на этот фрагмент
        pc.ontrack = (e) => {
          try {
            log('// ontrack', e.streams);
            const remoteStream = (e.streams && e.streams[0]) || e.stream || null;
            const aud = remoteAudio; // <audio id="remoteAudio">
            aud.srcObject = remoteStream;

            // comment: мониторинг удалённого потока
            // создаём/переиспользуем AudioContext для remote
            if (!window.remoteAudioContext) {
              window.remoteAudioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            const rac = window.remoteAudioContext;

            // очистим предыдущий интервал, если был
            if (window._remoteAnalyserInterval) {
              clearInterval(window._remoteAnalyserInterval);
              window._remoteAnalyserInterval = null;
            }

            try {
              const remoteSource = rac.createMediaStreamSource(remoteStream);
              const remoteAnalyser = rac.createAnalyser();
              remoteAnalyser.fftSize = 2048;
              remoteSource.connect(remoteAnalyser);
              const data = new Uint8Array(remoteAnalyser.fftSize);

              // измеряем RMS удалённого аудио
              window._remoteAnalyserInterval = setInterval(() => {
                try {
                  remoteAnalyser.getByteTimeDomainData(data);
                  let sum = 0;
                  for (let i = 0; i < data.length; i++) {
                    const v = (data[i] - 128) / 128;
                    sum += v * v;
                  }
                  const rms = Math.sqrt(sum / data.length);
                  const rms100 = Math.round(rms * 1000) / 1000;
                  log(`// remote-audio-level ${rms100}`);
                  // отправка на сервер для диагностики
                  try {
                    fetch('/debug/log', {
                      method: 'POST',
                      headers: { 'Content-Type': 'application/json' },
                      body: JSON.stringify({
                        ts: new Date().toISOString(),
                        src: 'client-audio-monitor',
                        kind: 'remote_audio_level',
                        data: { level: rms100 }
                      })
                    }).catch(() => {/* ignore */ });
                  } catch (e) { }
                } catch (err) { /* ignore per-interval errors */ }
              }, 250);
            } catch (err) {
              log('// remote analyser setup failed', String(err));
            }

            // comment: попытка play() — если пользователь уже сделал жест, play выполнится; иначе будет ошибка и мы ждём жеста
            if (audioEnabled) {
              aud.muted = false;
              aud.play().then(() => { log('// remote audio play OK'); })
                .catch((err) => { log('// remote audio play failed', String(err)); });
            } else {
              // если пользовательский жест не сделан — оставляем muted и ждем нажатия enableAudioBtn
              aud.muted = true;
              log('// ontrack but waiting for user gesture');
            }

          } catch (e) {
            log('// ontrack handler failed', e);
          }
        };

        if (localStream) localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        ws.send(JSON.stringify({ type: 'offer', sdp: offer.sdp }));
        log('// offer sent');
      });

      // ---------- ЗАМЕНИТЬ: handler для кнопки "Hang up" (повесить трубку) ----------
      // замените текущую реализацию document.getElementById('btnHang').addEventListener('click', ...)
      document.getElementById('btnHang').addEventListener('click', () => {
        if (pc) { pc.close(); pc = null; log('// pc closed'); }

        // comment: очистка локального анализатора/интервала
        try {
          if (window._localAnalyserInterval) { clearInterval(window._localAnalyserInterval); window._localAnalyserInterval = null; }
          if (window.localAudioContext) { try { window.localAudioContext.close(); } catch (e) { } window.localAudioContext = null; }
        } catch (e) { }

        // comment: очистка удалённого анализатора/интервала
        try {
          if (window._remoteAnalyserInterval) { clearInterval(window._remoteAnalyserInterval); window._remoteAnalyserInterval = null; }
          if (window.remoteAudioContext) { try { window.remoteAudioContext.close(); } catch (e) { } window.remoteAudioContext = null; }
        } catch (e) { }

        // comment: остановим локальные треки, если нужно (чтобы микрофон перестал работать)
        try {
          if (localStream) {
            localStream.getTracks().forEach(t => { try { t.stop(); } catch (e) { } });
            localStream = null;
            log('// local stream stopped');
          }
        } catch (e) { }
      });


    })();
  </script>
</body>

</html>