<!doctype html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>webrtc-minimal</title>
  <style>
    body {
      font-family: Arial, Helvetica, sans-serif;
      padding: 16px
    }

    button {
      padding: 8px 12px;
      margin: 6px
    }

    #log {
      white-space: pre-wrap;
      background: #f6f6f6;
      padding: 8px;
      border-radius: 6px;
      height: 240px;
      overflow: auto
    }
  </style>
</head>

<body>
  <h3>WebRTC minimal demo</h3>
  <div>
    <button id="btnLocal">Разрешить микрофон</button>
    <button id="btnCall">Позвонить (всем)</button>
    <button id="btnHang">Завершить</button>
  </div>
  <div>Ваш id: <span id="myId">-</span></div>
  <div>Логи:</div>
  <div id="log"></div>


  <audio id="remoteAudio" autoplay playsinline></audio>

  <script>
    (function () {
      const logEl = document.getElementById('log');
      const myIdEl = document.getElementById('myId');
      function log(...args) { console.log(...args); logEl.textContent += args.map(a => typeof a === 'object' ? JSON.stringify(a) : String(a)).join(' ') + '\n'; logEl.scrollTop = logEl.scrollHeight; }

      // кнопка для пользовательского жеста — создаём, если её нет в DOM
      let audioEnabled = false;
      let enableBtn = document.getElementById('enableAudioBtn');
      if (!enableBtn) {
        enableBtn = document.createElement('button');
        enableBtn.id = 'enableAudioBtn';
        enableBtn.textContent = 'Включить звук (нужен для авто-воспроизведения)';
        enableBtn.style.margin = '6px';
        document.body.insertBefore(enableBtn, document.getElementById('log'));
      }

      const remoteAudio = document.getElementById('remoteAudio');
      // если браузер требует пользовательский жест, держим audio muted до нажатия
      remoteAudio.muted = true;

      // enableBtn.addEventListener('click', async () => {
      //   try {
      //     // пытаемся play() — если получилось, считаем что autoplay разрешён
      //     await remoteAudio.play();
      //     remoteAudio.muted = false; // можно убрать заглушку
      //     audioEnabled = true;
      //     enableBtn.textContent = 'Звук включён';
      //     enableBtn.disabled = true;
      //     log('// audio enabled by user gesture');
      //   } catch (e) {
      //     // если play() не удалось — оставляем muted, но помечаем что пользователь сделал жест
      //     audioEnabled = true;
      //     enableBtn.textContent = 'Жест зафиксирован — звук разрешён после приема потока';
      //     enableBtn.disabled = true;
      //     log('// audio enable attempted, play() failed (это нормально в некоторых браузерах):', String(e));
      //   }
      // });

      enableBtn.addEventListener('click', async () => {
        try {
          // resume audio contexts if present or create remoteAudioContext placeholder
          if (window.localAudioContext && window.localAudioContext.state !== 'running') {
            await window.localAudioContext.resume();
          }
          if (window.remoteAudioContext && window.remoteAudioContext.state !== 'running') {
            await window.remoteAudioContext.resume();
          }

          // ensure we have a remoteAudioContext for later WebAudio use
          if (!window.remoteAudioContext) {
            window.remoteAudioContext = new (window.AudioContext || window.webkitAudioContext)();
            // create gain node ready (optional)
            window._remoteGainNode = window.remoteAudioContext.createGain();
            window._remoteGainNode.gain.value = 1.0;
            window._remoteGainNode.connect(window.remoteAudioContext.destination);
          }

          // unmute HTMLAudio and set volume to max
          remoteAudio.muted = false;
          try { remoteAudio.volume = 1.0; } catch (e) { /* ignore on browsers that forbid */ }

          audioEnabled = true;
          enableBtn.textContent = 'Звук включён';
          enableBtn.disabled = true;
          log('// audio enabled by user gesture — audio contexts resumed');

          // if stream already arrived — try play (await to catch AbortError)
          if (remoteAudio.srcObject) {
            try {
              if (remoteAudio.paused) {
                await remoteAudio.play();
                log('// remote audio play OK (from enableBtn)');
              }
            } catch (err) {
              log('// remoteAudio.play() failed in enableBtn:', String(err));
            }
          }

        } catch (e) {
          audioEnabled = true;
          enableBtn.textContent = 'Жест зафиксирован — звук разрешён после приема потока';
          enableBtn.disabled = true;
          log('// audio enable attempted, resume/play failed:', String(e));
        }
      });


      // WebSocket
      const wsProto = (location.protocol === 'https:') ? 'wss' : 'ws';
      const ws = new WebSocket(wsProto + '://' + location.host + '/ws');
      let myId = null;
      let pc = null;
      let localStream = null;

      function makeCallId() {
        try {
          if (myId) return `${myId}-${Date.now()}`;
        } catch (e) { }
        return `c-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`;
      }

      // добавляем публичный STUN, без TURN — для быстрых тестов
      const iceConfig = {
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' }
        ]
      };

      ws.addEventListener('open', () => log('// ws OPEN'));
      ws.addEventListener('message', async (ev) => {
        let msg; try { msg = JSON.parse(ev.data); } catch (e) { return; }
        log('// ws IN', msg.type || msg);

        if (msg.type === 'welcome') { myId = msg.id; myIdEl.textContent = myId; return; }

        if (msg.type === 'offer') {
          log('// got offer');
          if (pc) { pc.close(); pc = null; }
          const callId = msg.callId || makeCallId();
          pc = new RTCPeerConnection(iceConfig);
          pc.onicecandidate = (e) => { if (e.candidate) ws.send(JSON.stringify({ type: 'candidate', candidate: e.candidate, callId })); };
          pc.ontrack = async (e) => {
            try {
              log('// ontrack', e.streams);
              const remoteStream = (e.streams && e.streams[0]) || e.stream || null;
              const aud = remoteAudio; // <audio id="remoteAudio">
              aud.srcObject = remoteStream;

              // мониторинг удалённого потока
              // создаём/переиспользуем AudioContext для remote
              if (!window.remoteAudioContext) {
                window.remoteAudioContext = new (window.AudioContext || window.webkitAudioContext)();
              }
              const rac = window.remoteAudioContext;

              if (!window._remoteGainNode) {
                window._remoteGainNode = rac.createGain();
                window._remoteGainNode.gain.value = 1.0;
                window._remoteGainNode.connect(rac.destination);
              }

              // подключаем источник в gain (бережно — отключаем старый)
              if (window._remoteSourceNode) {
                try { window._remoteSourceNode.disconnect(); } catch (e) { }
                window._remoteSourceNode = null;
              }
              const remoteSource = rac.createMediaStreamSource(remoteStream);
              remoteSource.connect(window._remoteGainNode);
              window._remoteSourceNode = remoteSource;

              // очистим предыдущий интервал, если был
              // if (window._remoteAnalyserInterval) {
              //   clearInterval(window._remoteAnalyserInterval);
              //   window._remoteAnalyserInterval = null;
              // }

              // try {
              //   const remoteSource = rac.createMediaStreamSource(remoteStream);
              //   const remoteAnalyser = rac.createAnalyser();
              //   remoteAnalyser.fftSize = 2048;
              //   remoteSource.connect(remoteAnalyser);
              //   const data = new Uint8Array(remoteAnalyser.fftSize);

              //   // измеряем RMS удалённого аудио
              //   window._remoteAnalyserInterval = setInterval(() => {
              //     try {
              //       remoteAnalyser.getByteTimeDomainData(data);
              //       let sum = 0;
              //       for (let i = 0; i < data.length; i++) {
              //         const v = (data[i] - 128) / 128;
              //         sum += v * v;
              //       }
              //       const rms = Math.sqrt(sum / data.length);
              //       const rms100 = Math.round(rms * 1000) / 1000;
              //       log(`// remote-audio-level ${rms100}`);
              //       // отправка на сервер для диагностики
              //       try {
              //         fetch('/debug/log', {
              //           method: 'POST',
              //           headers: { 'Content-Type': 'application/json' },
              //           body: JSON.stringify({
              //             ts: new Date().toISOString(),
              //             src: 'client-audio-monitor',
              //             kind: 'remote_audio_level',
              //             data: { level: rms100 }
              //           })
              //         }).catch(() => {/* ignore */ });
              //       } catch (e) { }
              //     } catch (err) { /* ignore per-interval errors */ }
              //   }, 250);
              // } catch (err) {
              //   log('// remote analyser setup failed', String(err));
              // }

              // попытка play() — если пользователь уже сделал жест, play выполнится; иначе будет ошибка и мы ждём жеста
              // if (audioEnabled) {
              //   aud.muted = false;
              //   aud.play().then(() => { log('// remote audio play OK'); })
              //     .catch((err) => { log('// remote audio play failed', String(err)); });
              // } else {
              //   // если пользовательский жест не сделан — оставляем muted и ждем нажатия enableAudioBtn
              //   aud.muted = true;
              //   log('// ontrack but waiting for user gesture');
              // }

              if (audioEnabled) {
                try {
                  if (remoteAudio.paused) {
                    await remoteAudio.play();
                    log('// remote audio play OK (ontrack)');
                  }
                } catch (err) {
                  log('// remote audio play failed (ontrack):', String(err));
                }
              } else {
                log('// ontrack but waiting for user gesture');
              }

            } catch (e) {
              log('// ontrack handler failed', e);
            }
          };

          const diag = monitorPeerConnection(callId, pc);

          if (localStream) localStream.getTracks().forEach(t => pc.addTrack(t, localStream));
          await pc.setRemoteDescription({ type: 'offer', sdp: msg.sdp });
          const ans = await pc.createAnswer();
          await pc.setLocalDescription(ans);
          ws.send(JSON.stringify({ type: 'answer', sdp: ans.sdp, callId }));

          log('// answer sent');
          return;
        }

        if (msg.type === 'answer') {
          log('// got answer');
          if (!pc) return;
          try { await pc.setRemoteDescription({ type: 'answer', sdp: msg.sdp }); log('// remoteDescription(answer) set'); } catch (e) { log('// setRemoteDescription(answer) failed', e); }
          return;
        }

        if (msg.type === 'candidate') {
          log('// got candidate', msg.callId || '');
          if (!pc) { log('// no pc yet — ignored candidate'); return; }
          try { await pc.addIceCandidate(msg.candidate); log('// added candidate'); } catch (e) { log('// addIceCandidate failed', e); }
          return;
        }
      });

      document.getElementById('btnLocal').addEventListener('click', async () => {
        try {
          localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          log('// local stream acquired', localStream.getTracks().map(t => t.kind));

          if (!window.localAudioContext) {
            window.localAudioContext = new (window.AudioContext || window.webkitAudioContext)();
          }
          const lac = window.localAudioContext;

          if (window._localAnalyserInterval) {
            clearInterval(window._localAnalyserInterval);
            window._localAnalyserInterval = null;
          }

          const source = lac.createMediaStreamSource(localStream);
          const analyser = lac.createAnalyser();
          analyser.fftSize = 2048;
          source.connect(analyser);
          const data = new Uint8Array(analyser.fftSize);

          window._localAnalyserInterval = setInterval(() => {
            try {
              analyser.getByteTimeDomainData(data);
              let sum = 0;
              for (let i = 0; i < data.length; i++) {
                const v = (data[i] - 128) / 128;
                sum += v * v;
              }
              const rms = Math.sqrt(sum / data.length);
              const rms100 = Math.round(rms * 1000) / 1000;
              log(`// local-audio-level ${rms100}`);
              try {
                fetch('/debug/log', {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({
                    ts: new Date().toISOString(),
                    src: 'client-audio-monitor',
                    kind: 'local_audio_level',
                    data: { level: rms100 }
                  })
                }).catch(() => {/* ignore network errors */ });
              } catch (e) { }
            } catch (e) { /* ignore */ }
          }, 250);

        } catch (e) {
          log('// getUserMedia failed', e);
        }
      });


      document.getElementById('btnCall').addEventListener('click', async () => {
        log('// call: start');
        if (pc) { pc.close(); pc = null; }
        const callId = makeCallId();

        // const resp = await fetch('/get-turn-credentials');
        // const data = await resp.json();

        pc = new RTCPeerConnection({ iceConfig });
        window.pc = pc;
        pc.onicecandidate = (e) => { if (e.candidate) ws.send(JSON.stringify({ type: 'candidate', candidate: e.candidate, callId })); };
        pc.ontrack = (e) => {
          try {
            log('// ontrack', e.streams);
            const remoteStream = (e.streams && e.streams[0]) || e.stream || null;
            const aud = remoteAudio; // <audio id="remoteAudio">
            aud.srcObject = remoteStream;

            // мониторинг удалённого потока
            // создаём/переиспользуем AudioContext для remote
            if (!window.remoteAudioContext) {
              window.remoteAudioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            const rac = window.remoteAudioContext;

            // очистим предыдущий интервал, если был
            if (window._remoteAnalyserInterval) {
              clearInterval(window._remoteAnalyserInterval);
              window._remoteAnalyserInterval = null;
            }

            try {
              const remoteSource = rac.createMediaStreamSource(remoteStream);
              const remoteAnalyser = rac.createAnalyser();
              remoteAnalyser.fftSize = 2048;
              remoteSource.connect(remoteAnalyser);
              const data = new Uint8Array(remoteAnalyser.fftSize);

              // измеряем RMS удалённого аудио
              window._remoteAnalyserInterval = setInterval(() => {
                try {
                  remoteAnalyser.getByteTimeDomainData(data);
                  let sum = 0;
                  for (let i = 0; i < data.length; i++) {
                    const v = (data[i] - 128) / 128;
                    sum += v * v;
                  }
                  const rms = Math.sqrt(sum / data.length);
                  const rms100 = Math.round(rms * 1000) / 1000;
                  log(`// remote-audio-level ${rms100}`);
                  // отправка на сервер для диагностики
                  try {
                    fetch('/debug/log', {
                      method: 'POST',
                      headers: { 'Content-Type': 'application/json' },
                      body: JSON.stringify({
                        ts: new Date().toISOString(),
                        src: 'client-audio-monitor',
                        kind: 'remote_audio_level',
                        data: { level: rms100 }
                      })
                    }).catch(() => {/* ignore */ });
                  } catch (e) { }
                } catch (err) { /* ignore per-interval errors */ }
              }, 250);
            } catch (err) {
              log('// remote analyser setup failed', String(err));
            }

            // попытка play() — если пользователь уже сделал жест, play выполнится; иначе будет ошибка и мы ждём жеста
            if (audioEnabled) {
              aud.muted = false;
              aud.play().then(() => { log('// remote audio play OK'); })
                .catch((err) => { log('// remote audio play failed', String(err)); });
            } else {
              // если пользовательский жест не сделан — оставляем muted и ждем нажатия enableAudioBtn
              aud.muted = true;
              log('// ontrack but waiting for user gesture');
            }

          } catch (e) {
            log('// ontrack handler failed', e);
          }
        };

        const diag = monitorPeerConnection(callId, pc);
        if (localStream) localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        ws.send(JSON.stringify({ type: 'offer', sdp: offer.sdp }));
        log('// offer sent');
      });

      document.getElementById('btnHang').addEventListener('click', () => {
        if (pc) { pc.close(); pc = null; log('// pc closed'); }

        try {
          if (window._localAnalyserInterval) { clearInterval(window._localAnalyserInterval); window._localAnalyserInterval = null; }
          if (window.localAudioContext) { try { window.localAudioContext.close(); } catch (e) { } window.localAudioContext = null; }
        } catch (e) { }

        try {
          if (window._remoteAnalyserInterval) { clearInterval(window._remoteAnalyserInterval); window._remoteAnalyserInterval = null; }
          if (window.remoteAudioContext) { try { window.remoteAudioContext.close(); } catch (e) { } window.remoteAudioContext = null; }
        } catch (e) { }

        try {
          if (localStream) {
            localStream.getTracks().forEach(t => { try { t.stop(); } catch (e) { } });
            localStream = null;
            log('// local stream stopped');
          }
        } catch (e) { }
      });


      function monitorPeerConnection(callId, pc) {
        function clog(...args) { console.log('// diag', callId, ...args); }

        pc.addEventListener('iceconnectionstatechange', () => clog('iceConnectionState', pc.iceConnectionState));
        pc.addEventListener('connectionstatechange', () => clog('connectionState', pc.connectionState));
        pc.addEventListener('icegatheringstatechange', () => clog('iceGatheringState', pc.iceGatheringState));

        try {
          const senders = pc.getSenders().map(s => ({ id: s && s.track ? s.track.id : null, kind: s && s.track ? s.track.kind : null, enabled: s && s.track ? s.track.enabled : null }));
          const trans = pc.getTransceivers().map(t => ({ mid: t.mid, direction: t.direction, senderKind: (t.sender && t.sender.track && t.sender.track.kind) || null }));
          clog('initial-senders', senders, 'transceivers', trans);
        } catch (e) { clog('initial-senders-error', String(e)); }

        async function pollStatsOnce() {
          try {
            const stats = await pc.getStats();
            let candidatePair = null;
            let outbound = null;
            let inbound = null;
            stats.forEach(report => {
              if (report.type === 'candidate-pair' && report.selected) candidatePair = report;
              if (report.type === 'candidate-pair' && (report.nominated || report.selected)) candidatePair = candidatePair || report;
              if (report.type === 'outbound-rtp' && (report.kind === 'audio' || report.mediaType === 'audio')) outbound = outbound || report;
              if (report.type === 'inbound-rtp' && (report.kind === 'audio' || report.mediaType === 'audio')) inbound = inbound || report;
            });

            if (!candidatePair) {
              stats.forEach(report => { if (report.type === 'candidate-pair' && !candidatePair) candidatePair = report; });
            }

            const cpSummary = candidatePair ? {
              id: candidatePair.id,
              state: candidatePair.state || candidatePair.selected || null,
              writable: candidatePair.writable || candidatePair.writable === false ? candidatePair.writable : null,
              nominated: candidatePair.nominated || null,
              localCandidateId: candidatePair.localCandidateId || null,
              remoteCandidateId: candidatePair.remoteCandidateId || null,
              bytesSent: candidatePair.bytesSent || 0,
              bytesReceived: candidatePair.bytesReceived || 0,
              totalRoundTripTime: candidatePair.totalRoundTripTime || null
            } : null;

            const outSummary = outbound ? {
              id: outbound.id,
              type: outbound.type,
              bytesSent: outbound.bytesSent || 0,
              packetsSent: outbound.packetsSent || 0,
              codecId: outbound.codecId || null
            } : null;

            const inSummary = inbound ? {
              id: inbound.id,
              bytesReceived: inbound.bytesReceived || 0,
              packetsReceived: inbound.packetsReceived || 0,
              codecId: inbound.codecId || null
            } : null;

            clog('stats', { candidatePair: cpSummary, outbound: outSummary, inbound: inSummary });
            return { candidatePair: cpSummary, outbound: outSummary, inbound: inSummary };
          } catch (e) {
            clog('getStats-error', String(e));
            return null;
          }
        }

        let ticks = 0;
        const intervalId = setInterval(async () => {
          ticks += 1;
          const s = await pollStatsOnce();
          if (s && s.candidatePair && (s.candidatePair.writable === true || (s.outbound && s.outbound.bytesSent > 0))) {
            clog('media-path OK — writable or bytesSent > 0', s);
            // после подтверждения можно остановить интенсивный поллинг (оставим ещё пару проверок)
            if (ticks > 5) {
              clearInterval(intervalId);
            }
          }
          if (ticks > 60) clearInterval(intervalId);
        }, 1000);

        return {
          stop() { clearInterval(intervalId); },
          pollNow: pollStatsOnce
        };
      }

    })();
  </script>
</body>

</html>